{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPOz5bQ+Mbnb8I9tXvBgVp2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanishy7777/Pix2Pix-Pytorch/blob/main/Implementing_Pix2Pix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8anBgfrictK",
        "outputId": "57a78392-d5b1-4f44-fd33-72f2f0cc9715"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IUlEhs2_QlOc"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/maps.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('./data')\n",
        "\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/facades.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('./data')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement Mpap Dataset, Facades Dataset\n",
        "# Implement Discriminator\n",
        "# Implement Generator"
      ],
      "metadata": {
        "id": "GUP_UdQTSUnU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import functools\n",
        "from torch.optim import lr_scheduler"
      ],
      "metadata": {
        "id": "cT2YlZURmtFp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    \"\"\" PatchGAN Discriminator\n",
        "\n",
        "    Here 70x70 Discriminator Architecture is used\n",
        "    C64-C128-C256-C512\n",
        "\n",
        "    After the last layer convolution is applied to map to a 1D prediction\n",
        "    All ReLUs are Leaky with 0.2 slope\n",
        "    BatchNorm is not applied to the first C64 layer\n",
        "\n",
        "    Here Ck denote a Convolution-BatchNorm-ReLU layer\n",
        "    with k filters.\n",
        "\n",
        "    CDk denotes a Convolution-BatchNorm-Dropout-ReLU layer\n",
        "    with a dropout rate of 50%.\n",
        "\n",
        "    All convolutions are 4x4 spatial filters applied with stride 2.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, input_channels=3, hidden_units=[64, 128, 256, 512]):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initial Block (dosent have BatchNorm as per the paper)\n",
        "        sequence = [nn.Conv2d(input_channels, hidden_units[0], kernel_size=4, stride=2, padding=1), nn.LeakyReLU(0.2, True)]\n",
        "\n",
        "        for l in range(1, len(hidden_units)):  # gradually increase the number of filters\n",
        "            sequence += [\n",
        "                nn.Conv2d(hidden_units[l-1], hidden_units[l], kernel_size=4, stride=2, padding=1),\n",
        "                nn.BatchNorm2d(hidden_units[l]),\n",
        "                nn.LeakyReLU(0.2)\n",
        "            ]\n",
        "\n",
        "        sequence += [nn.Conv2d(hidden_units[-1], 1, kernel_size=4, stride=1, padding=1)]  # output 1 channel prediction map\n",
        "        self.model = nn.Sequential(*sequence)\n",
        "\n",
        "    def forward(self, input):\n",
        "      \"\"\"Standard forward.\"\"\"\n",
        "\n",
        "      return self.model(input)"
      ],
      "metadata": {
        "id": "6MREyveBmZJv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UnetGenerator(nn.Module):\n",
        "    \"\"\"Create a Unet-based generator\"\"\"\n",
        "\n",
        "    def __init__(self, input_nc, output_nc, num_downs, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
        "        \"\"\"Construct a Unet generator\n",
        "        Parameters:\n",
        "            input_nc (int)  -- the number of channels in input images\n",
        "            output_nc (int) -- the number of channels in output images\n",
        "            num_downs (int) -- the number of downsamplings in UNet. For example, # if |num_downs| == 7,\n",
        "                                image of size 128x128 will become of size 1x1 # at the bottleneck\n",
        "            ngf (int)       -- the number of filters in the last conv layer\n",
        "            norm_layer      -- normalization layer\n",
        "\n",
        "        We construct the U-Net from the innermost layer to the outermost layer.\n",
        "        It is a recursive process.\n",
        "        \"\"\"\n",
        "        super(UnetGenerator, self).__init__()\n",
        "        # construct unet structure\n",
        "        unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=None, norm_layer=norm_layer, innermost=True)  # add the innermost layer\n",
        "        for i in range(num_downs - 5):          # add intermediate layers with ngf * 8 filters\n",
        "            unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer, use_dropout=use_dropout)\n",
        "        # gradually reduce the number of filters from ngf * 8 to ngf\n",
        "        unet_block = UnetSkipConnectionBlock(ngf * 4, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
        "        unet_block = UnetSkipConnectionBlock(ngf * 2, ngf * 4, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
        "        unet_block = UnetSkipConnectionBlock(ngf, ngf * 2, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
        "        self.model = UnetSkipConnectionBlock(output_nc, ngf, input_nc=input_nc, submodule=unet_block, outermost=True, norm_layer=norm_layer)  # add the outermost layer\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"Standard forward\"\"\"\n",
        "        return self.model(input)\n",
        "\n",
        "\n",
        "class UnetSkipConnectionBlock(nn.Module):\n",
        "    \"\"\"Defines the Unet submodule with skip connection.\n",
        "        X -------------------identity----------------------\n",
        "        |-- downsampling -- |submodule| -- upsampling --|\n",
        "\n",
        "        Encoder:\n",
        "        C64-C128-C256-C512-C512-C512-C512-C512\n",
        "\n",
        "        Unet Decoder:\n",
        "        CD512-CD1024-CD1024-C1024-C1024-C512-C256-C128\n",
        "\n",
        "\n",
        "        After the last layer in the decoder, a convolution is applied\n",
        "        to map to the number of output channels followed by a Tanh\n",
        "        function.\n",
        "\n",
        "        BatchNorm is not applied to the first C64 layer in the encoder.\n",
        "\n",
        "        All ReLUs in the encoder are leaky, with slope 0.2, while ReLUs\n",
        "        in the decoder are not leaky.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, outer_channels, inner_channels, input_channels,\n",
        "                 submodule=None, outermost=False, innermost=False, use_dropout=False):\n",
        "        \"\"\"Construct a Unet submodule with skip connections.\n",
        "\n",
        "        Parameters:\n",
        "            outer_nc (int) -- the number of filters in the outer conv layer\n",
        "            inner_nc (int) -- the number of filters in the inner conv layer\n",
        "            input_nc (int) -- the number of channels in input images/features\n",
        "            submodule (UnetSkipConnectionBlock) -- previously defined submodules\n",
        "            outermost (bool)    -- if this module is the outermost module\n",
        "            innermost (bool)    -- if this module is the innermost module\n",
        "            norm_layer          -- normalization layer\n",
        "            use_dropout (bool)  -- if use dropout layers.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.outermost = outermost\n",
        "\n",
        "        if input_nc is None:\n",
        "            input_nc = outer_channels\n",
        "\n",
        "        downconv = nn.Conv2d(input_channels, inner_channels, kernel_size=4, stride=2, padding=1)\n",
        "        downrelu = nn.LeakyReLU(0.2, True)\n",
        "        downnorm = nn.BatchNorm2d(inner_channels)\n",
        "\n",
        "        upnorm = nn.BatchNorm2d(outer_channels)\n",
        "        uprelu = nn.ReLU(True)\n",
        "\n",
        "\n",
        "        if outermost:\n",
        "            upconv = nn.ConvTranspose2d(inner_channels * 2, outer_channels, kernel_size=4, stride=2, padding=1)\n",
        "            down = [downconv]\n",
        "            up = [uprelu, upconv, nn.Tanh()]\n",
        "            model = down + [submodule] + up\n",
        "\n",
        "        elif innermost:\n",
        "                                      # 512             512(same as no of filters)\n",
        "            upconv = nn.ConvTranspose2d(inner_channels, outer_channels, kernel_size=4, stride=2, padding=1)\n",
        "            down = [downrelu, downconv]\n",
        "            up = [uprelu, upconv, upnorm]\n",
        "            model = down + up\n",
        "        else:\n",
        "            upconv = nn.ConvTranspose2d(inner_channels * 2, outer_channels, kernel_size=4, stride=2, padding=1)\n",
        "            down = [downrelu, downconv, downnorm]\n",
        "            up = [uprelu, upconv, upnorm]\n",
        "\n",
        "            if use_dropout:\n",
        "                model = down + [submodule] + up + [nn.Dropout(0.5)]\n",
        "            else:\n",
        "                model = down + [submodule] + up\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.outermost:\n",
        "            return self.model(x)\n",
        "        else:   # add skip connections\n",
        "            return torch.cat([x, self.model(x)], 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "LVm6IiEptTei"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References"
      ],
      "metadata": {
        "id": "hqbYXSlK-wxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n",
        "2. https://github.com/aladdinpersson/Machine-Learning-Collection\n",
        "3. https://phillipi.github.io/pix2pix/"
      ],
      "metadata": {
        "id": "j5dD1K_D-0OF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1."
      ],
      "metadata": {
        "id": "YnooLsOY-yQ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}