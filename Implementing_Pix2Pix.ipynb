{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPyzliZg79TYrnzCazhU/2L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanishy7777/Pix2Pix-Pytorch/blob/main/Implementing_Pix2Pix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8anBgfrictK",
        "outputId": "1864f287-6d37-4fd5-b461-ecd59fb5b23c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IUlEhs2_QlOc"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/maps.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('./data')\n",
        "\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/facades.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('./data')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement Map Dataset, Facades Dataset\n",
        "# Implement Discriminator\n",
        "# Implement Generator"
      ],
      "metadata": {
        "id": "GUP_UdQTSUnU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import functools\n",
        "from torch.optim import lr_scheduler"
      ],
      "metadata": {
        "id": "cT2YlZURmtFp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class NLayerDiscriminator(nn.Module):\n",
        "    \"\"\"Defines a PatchGAN discriminator\"\"\"\n",
        "\n",
        "    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d):\n",
        "        \"\"\"Construct a PatchGAN discriminator\n",
        "\n",
        "        Parameters:\n",
        "            input_nc (int)  -- the number of channels in input images\n",
        "            ndf (int)       -- the number of filters in the last conv layer\n",
        "            n_layers (int)  -- the number of conv layers in the discriminator\n",
        "            norm_layer      -- normalization layer\n",
        "        \"\"\"\n",
        "        super(NLayerDiscriminator, self).__init__()\n",
        "        if type(norm_layer) == functools.partial:  # no need to use bias as BatchNorm2d has affine parameters\n",
        "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
        "        else:\n",
        "            use_bias = norm_layer == nn.InstanceNorm2d\n",
        "\n",
        "        kw = 4\n",
        "        padw = 1\n",
        "        sequence = [nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]\n",
        "        nf_mult = 1\n",
        "        nf_mult_prev = 1\n",
        "        for n in range(1, n_layers):  # gradually increase the number of filters\n",
        "            nf_mult_prev = nf_mult\n",
        "            nf_mult = min(2 ** n, 8)\n",
        "            sequence += [\n",
        "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
        "                norm_layer(ndf * nf_mult),\n",
        "                nn.LeakyReLU(0.2, True)\n",
        "            ]\n",
        "\n",
        "        nf_mult_prev = nf_mult\n",
        "        nf_mult = min(2 ** n_layers, 8)\n",
        "        sequence += [\n",
        "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
        "            norm_layer(ndf * nf_mult),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        ]\n",
        "\n",
        "        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]  # output 1 channel prediction map\n",
        "        self.model = nn.Sequential(*sequence)\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"Standard forward.\"\"\"\n",
        "        return self.model(input)"
      ],
      "metadata": {
        "id": "MvVtL6blypI-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    \"\"\" PatchGAN Discriminator\n",
        "\n",
        "    70x70 Discriminator Architecture\n",
        "    C64-C128-C256-C512\n",
        "\n",
        "    After last layer convolution is applied to map to a 1D prediction, followed by a sigmoid function\n",
        "    All ReLUs are Leaky with 0.2 slope\n",
        "    BatchNorm is not applied to the first C64 layer\n",
        "\n",
        "    Here Ck denote a Convolution-BatchNorm-ReLU layer\n",
        "    with k filters.\n",
        "\n",
        "    CDk denotes a Convolution-BatchNorm-Dropout-ReLU layer\n",
        "    with a dropout rate of 50%. All convolutions are 4x4\n",
        "    spatial filters applied with stride 2.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, input_channels=3, hidden_units=[64, 128, 256, 512]):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initial Block (dosent have BatchNorm as per the paper)\n",
        "        sequence = [nn.Conv2d(input_channels, hidden_units[0], kernel_size=4, stride=2, padding=1), nn.LeakyReLU(0.2, True)]\n",
        "\n",
        "        for l in range(1, len(hidden_units)):  # gradually increase the number of filters\n",
        "            sequence += [\n",
        "                nn.Conv2d(hidden_units[l-1], hidden_units[l], kernel_size=4, stride=2, padding=1),\n",
        "                nn.BatchNorm2d(hidden_units[l]),\n",
        "                nn.LeakyReLU(0.2)\n",
        "            ]\n",
        "\n",
        "        sequence += [nn.Conv2d(hidden_units[-1], 1, kernel_size=4, stride=1, padding=1)]  # output 1 channel prediction map\n",
        "        self.model = nn.Sequential(*sequence)\n",
        "\n",
        "    def forward(self, input):\n",
        "      \"\"\"Standard forward.\"\"\"\n",
        "\n",
        "      return self.model(input)"
      ],
      "metadata": {
        "id": "6MREyveBmZJv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UnetGenerator(nn.Module):\n",
        "    \"\"\"Create a Unet-based generator\"\"\"\n",
        "\n",
        "    def __init__(self, input_nc, output_nc, num_downs, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
        "        \"\"\"Construct a Unet generator\n",
        "        Parameters:\n",
        "            input_nc (int)  -- the number of channels in input images\n",
        "            output_nc (int) -- the number of channels in output images\n",
        "            num_downs (int) -- the number of downsamplings in UNet. For example, # if |num_downs| == 7,\n",
        "                                image of size 128x128 will become of size 1x1 # at the bottleneck\n",
        "            ngf (int)       -- the number of filters in the last conv layer\n",
        "            norm_layer      -- normalization layer\n",
        "\n",
        "        We construct the U-Net from the innermost layer to the outermost layer.\n",
        "        It is a recursive process.\n",
        "        \"\"\"\n",
        "        super(UnetGenerator, self).__init__()\n",
        "        # construct unet structure\n",
        "        unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=None, norm_layer=norm_layer, innermost=True)  # add the innermost layer\n",
        "        for i in range(num_downs - 5):          # add intermediate layers with ngf * 8 filters\n",
        "            unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer, use_dropout=use_dropout)\n",
        "        # gradually reduce the number of filters from ngf * 8 to ngf\n",
        "        unet_block = UnetSkipConnectionBlock(ngf * 4, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
        "        unet_block = UnetSkipConnectionBlock(ngf * 2, ngf * 4, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
        "        unet_block = UnetSkipConnectionBlock(ngf, ngf * 2, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
        "        self.model = UnetSkipConnectionBlock(output_nc, ngf, input_nc=input_nc, submodule=unet_block, outermost=True, norm_layer=norm_layer)  # add the outermost layer\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"Standard forward\"\"\"\n",
        "        return self.model(input)\n",
        "\n",
        "\n",
        "class UnetSkipConnectionBlock(nn.Module):\n",
        "    \"\"\"Defines the Unet submodule with skip connection.\n",
        "        X -------------------identity----------------------\n",
        "        |-- downsampling -- |submodule| -- upsampling --|\n",
        "\n",
        "        Encoder:\n",
        "        C64-C128-C256-C512-C512-C512-C512-C512\n",
        "\n",
        "        Unet Decoder:\n",
        "        CD512-CD1024-CD1024-C1024-C1024-C512-C256-C128\n",
        "\n",
        "\n",
        "        After the last layer in the decoder, a convolution is applied\n",
        "        to map to the number of output channels followed by a Tanh\n",
        "        function.\n",
        "\n",
        "        BatchNorm is not applied to the first C64 layer in the encoder.\n",
        "\n",
        "        All ReLUs in the encoder are leaky, with slope 0.2, while ReLUs\n",
        "        in the decoder are not leaky.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, outer_channels, inner_channels, input_channels,\n",
        "                 submodule=None, outermost=False, innermost=False, use_dropout=False):\n",
        "        \"\"\"Construct a Unet submodule with skip connections.\n",
        "\n",
        "        Parameters:\n",
        "            outer_nc (int) -- the number of filters in the outer conv layer\n",
        "            inner_nc (int) -- the number of filters in the inner conv layer\n",
        "            input_nc (int) -- the number of channels in input images/features\n",
        "            submodule (UnetSkipConnectionBlock) -- previously defined submodules\n",
        "            outermost (bool)    -- if this module is the outermost module\n",
        "            innermost (bool)    -- if this module is the innermost module\n",
        "            norm_layer          -- normalization layer\n",
        "            use_dropout (bool)  -- if use dropout layers.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.outermost = outermost\n",
        "\n",
        "        if input_nc is None:\n",
        "            input_nc = outer_channels\n",
        "\n",
        "        downconv = nn.Conv2d(input_channels, inner_channels, kernel_size=4, stride=2, padding=1)\n",
        "        downrelu = nn.LeakyReLU(0.2, True)\n",
        "        downnorm = nn.BatchNorm2d(inner_channels)\n",
        "\n",
        "        upnorm = nn.BatchNorm2d(outer_channels)\n",
        "        uprelu = nn.ReLU(True)\n",
        "\n",
        "\n",
        "        if outermost:\n",
        "            upconv = nn.ConvTranspose2d(inner_channels * 2, outer_channels, kernel_size=4, stride=2, padding=1)\n",
        "            down = [downconv]\n",
        "            up = [uprelu, upconv, nn.Tanh()]\n",
        "            model = down + [submodule] + up\n",
        "\n",
        "        elif innermost:\n",
        "                                      # 512             512(same as no of filters)\n",
        "            upconv = nn.ConvTranspose2d(inner_channels, outer_channels, kernel_size=4, stride=2, padding=1)\n",
        "            down = [downrelu, downconv]\n",
        "            up = [uprelu, upconv, upnorm]\n",
        "            model = down + up\n",
        "        else:\n",
        "            upconv = nn.ConvTranspose2d(inner_channels * 2, outer_channels, kernel_size=4, stride=2, padding=1)\n",
        "            down = [downrelu, downconv, downnorm]\n",
        "            up = [uprelu, upconv, upnorm]\n",
        "\n",
        "            if use_dropout:\n",
        "                model = down + [submodule] + up + [nn.Dropout(0.5)]\n",
        "            else:\n",
        "                model = down + [submodule] + up\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.outermost:\n",
        "            return self.model(x)\n",
        "        else:   # add skip connections\n",
        "            return torch.cat([x, self.model(x)], 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "LVm6IiEptTei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchviz import make_dot\n",
        "\n",
        "# model = UnetGenerator()\n",
        "# y = model(x)\n",
        "\n",
        "# make_dot(y.mean(), params=dict(model.named_parameters()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Cvz_Fz1oKFjg",
        "outputId": "aac569ea-acff-44b7-a2c1-da6a68cfd45f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Net' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2616c1c6d60d>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchviz\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_dot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Net' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8GsdReloKR2x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}